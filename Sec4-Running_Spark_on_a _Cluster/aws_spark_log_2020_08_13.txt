                                          .4 KB, free: 414.4 MB)
20/08/13 20:38:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-213.ec2.internal:33309 (size:                                                                                                                                    7.4 KB, free: 414.4 MB)
20/08/13 20:38:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-213.ec2.internal:33037 (size:                                                                                                                                    7.4 KB, free: 414.4 MB)
20/08/13 20:38:31 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-92-213.ec2.internal:46457 with 414.                                                                                                                                   4 MB RAM, BlockManagerId(73, ip-172-31-92-213.ec2.internal, 46457, None)
20/08/13 20:38:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.29:53                                                                                                                                   088
20/08/13 20:38:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-29.ec2.internal:33233 (size: 7                                                                                                                                   .4 KB, free: 414.4 MB)
20/08/13 20:38:32 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Exe                                                                                                                                   cutor) (172.31.92.213:34200) with ID 75
20/08/13 20:38:32 INFO ExecutorAllocationManager: New executor 75 has registered (new total is 22)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 84.0 in stage 2.0 (TID 234, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   5, partition 84, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 85.0 in stage 2.0 (TID 235, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   5, partition 85, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 86.0 in stage 2.0 (TID 236, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   5, partition 86, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 87.0 in stage 2.0 (TID 237, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   5, partition 87, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.29:53                                                                                                                                   090
20/08/13 20:38:32 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Exe                                                                                                                                   cutor) (172.31.92.213:34198) with ID 74
20/08/13 20:38:32 INFO ExecutorAllocationManager: New executor 74 has registered (new total is 23)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 88.0 in stage 2.0 (TID 238, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   4, partition 88, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 89.0 in stage 2.0 (TID 239, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   4, partition 89, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 90.0 in stage 2.0 (TID 240, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   4, partition 90, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO TaskSetManager: Starting task 91.0 in stage 2.0 (TID 241, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   4, partition 91, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.213:3                                                                                                                                   4184
20/08/13 20:38:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.213:3                                                                                                                                   4182
20/08/13 20:38:33 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-92-213.ec2.internal:45061 with 414.                                                                                                                                   4 MB RAM, BlockManagerId(74, ip-172-31-92-213.ec2.internal, 45061, None)
20/08/13 20:38:34 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-92-213.ec2.internal:42859 with 414.                                                                                                                                   4 MB RAM, BlockManagerId(75, ip-172-31-92-213.ec2.internal, 42859, None)
20/08/13 20:38:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-213.ec2.internal:46457 (size:                                                                                                                                    7.4 KB, free: 414.4 MB)
20/08/13 20:38:35 INFO YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 77.
20/08/13 20:38:35 INFO DAGScheduler: Executor lost: 77 (epoch 2)
20/08/13 20:38:35 INFO BlockManagerMasterEndpoint: Trying to remove executor 77 from BlockManagerMaster.
20/08/13 20:38:35 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(77, ip-172-31-94-35.ec2.internal,                                                                                                                                    39117, None)
20/08/13 20:38:35 INFO BlockManagerMaster: Removed 77 successfully in removeExecutor
20/08/13 20:38:35 ERROR YarnScheduler: Lost executor 77 on ip-172-31-94-35.ec2.internal: Container killed by YARN for exce                                                                                                                                   eding memory limits.  1.8 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disab                                                                                                                                   ling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:35 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 77 for reason Cont                                                                                                                                   ainer killed by YARN for exceeding memory limits.  1.8 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.exe                                                                                                                                   cutor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:35 WARN TaskSetManager: Lost task 18.2 in stage 2.0 (TID 209, ip-172-31-94-35.ec2.internal, executor 77): E                                                                                                                                   xecutorLostFailure (executor 77 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.8 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:35 WARN TaskSetManager: Lost task 11.2 in stage 2.0 (TID 208, ip-172-31-94-35.ec2.internal, executor 77): E                                                                                                                                   xecutorLostFailure (executor 77 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.8 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:35 WARN TaskSetManager: Lost task 4.2 in stage 2.0 (TID 207, ip-172-31-94-35.ec2.internal, executor 77): Ex                                                                                                                                   ecutorLostFailure (executor 77 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding m                                                                                                                                   emory limits.  1.8 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling ya                                                                                                                                   rn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:35 WARN TaskSetManager: Lost task 25.2 in stage 2.0 (TID 206, ip-172-31-94-35.ec2.internal, executor 77): E                                                                                                                                   xecutorLostFailure (executor 77 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.8 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:35 INFO BlockManagerMaster: Removal of executor 77 requested
20/08/13 20:38:35 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 77
20/08/13 20:38:35 INFO BlockManagerMasterEndpoint: Trying to remove executor 77 from BlockManagerMaster.
20/08/13 20:38:35 INFO ExecutorAllocationManager: Existing executor 77 has been removed (new total is 22)
20/08/13 20:38:35 WARN ExecutorAllocationManager: Attempted to mark unknown executor 77 idle
20/08/13 20:38:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.213:3                                                                                                                                   4192
20/08/13 20:38:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-213.ec2.internal:45061 (size:                                                                                                                                    7.4 KB, free: 414.4 MB)
20/08/13 20:38:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-213.ec2.internal:42859 (size:                                                                                                                                    7.4 KB, free: 414.4 MB)
20/08/13 20:38:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.213:3                                                                                                                                   4200
20/08/13 20:38:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.213:3                                                                                                                                   4198
20/08/13 20:38:39 INFO YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 80.
20/08/13 20:38:39 INFO DAGScheduler: Executor lost: 80 (epoch 2)
20/08/13 20:38:39 INFO BlockManagerMasterEndpoint: Trying to remove executor 80 from BlockManagerMaster.
20/08/13 20:38:39 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(80, ip-172-31-91-218.ec2.internal                                                                                                                                   , 44903, None)
20/08/13 20:38:39 INFO BlockManagerMaster: Removed 80 successfully in removeExecutor
20/08/13 20:38:39 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 80 for reason Cont                                                                                                                                   ainer killed by YARN for exceeding memory limits.  1.5 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.exe                                                                                                                                   cutor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:39 ERROR YarnScheduler: Lost executor 80 on ip-172-31-91-218.ec2.internal: Container killed by YARN for exc                                                                                                                                   eeding memory limits.  1.5 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disa                                                                                                                                   bling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:39 WARN TaskSetManager: Lost task 68.0 in stage 2.0 (TID 218, ip-172-31-91-218.ec2.internal, executor 80):                                                                                                                                    ExecutorLostFailure (executor 80 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.5 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:39 WARN TaskSetManager: Lost task 70.0 in stage 2.0 (TID 220, ip-172-31-91-218.ec2.internal, executor 80):                                                                                                                                    ExecutorLostFailure (executor 80 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.5 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:39 WARN TaskSetManager: Lost task 69.0 in stage 2.0 (TID 219, ip-172-31-91-218.ec2.internal, executor 80):                                                                                                                                    ExecutorLostFailure (executor 80 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.5 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:39 WARN TaskSetManager: Lost task 71.0 in stage 2.0 (TID 221, ip-172-31-91-218.ec2.internal, executor 80):                                                                                                                                    ExecutorLostFailure (executor 80 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.5 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:39 INFO BlockManagerMaster: Removal of executor 80 requested
20/08/13 20:38:39 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 80
20/08/13 20:38:39 INFO BlockManagerMasterEndpoint: Trying to remove executor 80 from BlockManagerMaster.
20/08/13 20:38:39 INFO ExecutorAllocationManager: Existing executor 80 has been removed (new total is 21)
20/08/13 20:38:40 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Exe                                                                                                                                   cutor) (172.31.92.213:34216) with ID 76
20/08/13 20:38:40 INFO ExecutorAllocationManager: New executor 76 has registered (new total is 22)
20/08/13 20:38:40 INFO TaskSetManager: Starting task 71.1 in stage 2.0 (TID 242, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   6, partition 71, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:40 INFO TaskSetManager: Starting task 69.1 in stage 2.0 (TID 243, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   6, partition 69, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:40 INFO TaskSetManager: Starting task 70.1 in stage 2.0 (TID 244, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   6, partition 70, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:40 INFO TaskSetManager: Starting task 68.1 in stage 2.0 (TID 245, ip-172-31-92-213.ec2.internal, executor 7                                                                                                                                   6, partition 68, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:42 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-92-213.ec2.internal:43373 with 414.                                                                                                                                   4 MB RAM, BlockManagerId(76, ip-172-31-92-213.ec2.internal, 43373, None)
20/08/13 20:38:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-213.ec2.internal:43373 (size:                                                                                                                                    7.4 KB, free: 414.4 MB)
20/08/13 20:38:45 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Exe                                                                                                                                   cutor) (172.31.89.202:43008) with ID 82
20/08/13 20:38:45 INFO ExecutorAllocationManager: New executor 82 has registered (new total is 23)
20/08/13 20:38:45 INFO TaskSetManager: Starting task 25.3 in stage 2.0 (TID 246, ip-172-31-89-202.ec2.internal, executor 8                                                                                                                                   2, partition 25, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:45 INFO TaskSetManager: Starting task 4.3 in stage 2.0 (TID 247, ip-172-31-89-202.ec2.internal, executor 82                                                                                                                                   , partition 4, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:45 INFO TaskSetManager: Starting task 11.3 in stage 2.0 (TID 248, ip-172-31-89-202.ec2.internal, executor 8                                                                                                                                   2, partition 11, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:45 INFO TaskSetManager: Starting task 18.3 in stage 2.0 (TID 249, ip-172-31-89-202.ec2.internal, executor 8                                                                                                                                   2, partition 18, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:46 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-89-202.ec2.internal:44939 with 414.                                                                                                                                   4 MB RAM, BlockManagerId(82, ip-172-31-89-202.ec2.internal, 44939, None)
20/08/13 20:38:47 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-89-202.ec2.internal:44939 (size:                                                                                                                                    7.4 KB, free: 414.4 MB)
20/08/13 20:38:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.89.202:4                                                                                                                                   3008
20/08/13 20:38:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.213:3                                                                                                                                   4216
20/08/13 20:38:49 INFO YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 79.
20/08/13 20:38:49 INFO DAGScheduler: Executor lost: 79 (epoch 2)
20/08/13 20:38:49 INFO BlockManagerMasterEndpoint: Trying to remove executor 79 from BlockManagerMaster.
20/08/13 20:38:49 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(79, ip-172-31-92-29.ec2.internal,                                                                                                                                    36633, None)
20/08/13 20:38:49 INFO BlockManagerMaster: Removed 79 successfully in removeExecutor
20/08/13 20:38:49 ERROR YarnScheduler: Lost executor 79 on ip-172-31-92-29.ec2.internal: Container killed by YARN for exce                                                                                                                                   eding memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disab                                                                                                                                   ling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:49 WARN TaskSetManager: Lost task 73.0 in stage 2.0 (TID 223, ip-172-31-92-29.ec2.internal, executor 79): E                                                                                                                                   xecutorLostFailure (executor 79 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:49 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 79 for reason Cont                                                                                                                                   ainer killed by YARN for exceeding memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.exe                                                                                                                                   cutor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:49 WARN TaskSetManager: Lost task 75.0 in stage 2.0 (TID 225, ip-172-31-92-29.ec2.internal, executor 79): E                                                                                                                                   xecutorLostFailure (executor 79 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:49 WARN TaskSetManager: Lost task 72.0 in stage 2.0 (TID 222, ip-172-31-92-29.ec2.internal, executor 79): E                                                                                                                                   xecutorLostFailure (executor 79 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:49 WARN TaskSetManager: Lost task 74.0 in stage 2.0 (TID 224, ip-172-31-92-29.ec2.internal, executor 79): E                                                                                                                                   xecutorLostFailure (executor 79 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:49 INFO BlockManagerMaster: Removal of executor 79 requested
20/08/13 20:38:49 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 79
20/08/13 20:38:49 INFO BlockManagerMasterEndpoint: Trying to remove executor 79 from BlockManagerMaster.
20/08/13 20:38:49 INFO ExecutorAllocationManager: Existing executor 79 has been removed (new total is 22)
20/08/13 20:38:51 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Exe                                                                                                                                   cutor) (172.31.81.193:44488) with ID 71
20/08/13 20:38:51 INFO ExecutorAllocationManager: New executor 71 has registered (new total is 23)
20/08/13 20:38:51 INFO TaskSetManager: Starting task 74.1 in stage 2.0 (TID 250, ip-172-31-81-193.ec2.internal, executor 7                                                                                                                                   1, partition 74, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:51 INFO TaskSetManager: Starting task 72.1 in stage 2.0 (TID 251, ip-172-31-81-193.ec2.internal, executor 7                                                                                                                                   1, partition 72, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:51 INFO TaskSetManager: Starting task 75.1 in stage 2.0 (TID 252, ip-172-31-81-193.ec2.internal, executor 7                                                                                                                                   1, partition 75, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:51 INFO TaskSetManager: Starting task 73.1 in stage 2.0 (TID 253, ip-172-31-81-193.ec2.internal, executor 7                                                                                                                                   1, partition 73, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:51 INFO YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 57.
20/08/13 20:38:51 INFO DAGScheduler: Executor lost: 57 (epoch 2)
20/08/13 20:38:51 INFO BlockManagerMasterEndpoint: Trying to remove executor 57 from BlockManagerMaster.
20/08/13 20:38:51 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(57, ip-172-31-81-193.ec2.internal                                                                                                                                   , 43879, None)
20/08/13 20:38:51 INFO BlockManagerMaster: Removed 57 successfully in removeExecutor
20/08/13 20:38:51 ERROR YarnScheduler: Lost executor 57 on ip-172-31-81-193.ec2.internal: Container killed by YARN for exc                                                                                                                                   eeding memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disa                                                                                                                                   bling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:51 WARN TaskSetManager: Lost task 49.0 in stage 2.0 (TID 151, ip-172-31-81-193.ec2.internal, executor 57):                                                                                                                                    ExecutorLostFailure (executor 57 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:51 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 57 for reason Cont                                                                                                                                   ainer killed by YARN for exceeding memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.exe                                                                                                                                   cutor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:51 WARN TaskSetManager: Lost task 48.0 in stage 2.0 (TID 150, ip-172-31-81-193.ec2.internal, executor 57):                                                                                                                                    ExecutorLostFailure (executor 57 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:51 WARN TaskSetManager: Lost task 51.0 in stage 2.0 (TID 153, ip-172-31-81-193.ec2.internal, executor 57):                                                                                                                                    ExecutorLostFailure (executor 57 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:51 WARN TaskSetManager: Lost task 50.0 in stage 2.0 (TID 152, ip-172-31-81-193.ec2.internal, executor 57):                                                                                                                                    ExecutorLostFailure (executor 57 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:51 INFO BlockManagerMaster: Removal of executor 57 requested
20/08/13 20:38:51 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 57
20/08/13 20:38:51 INFO BlockManagerMasterEndpoint: Trying to remove executor 57 from BlockManagerMaster.
20/08/13 20:38:51 INFO ExecutorAllocationManager: Existing executor 57 has been removed (new total is 22)
20/08/13 20:38:52 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Exe                                                                                                                                   cutor) (172.31.92.29:53174) with ID 81
20/08/13 20:38:52 INFO ExecutorAllocationManager: New executor 81 has registered (new total is 23)
20/08/13 20:38:52 INFO TaskSetManager: Starting task 50.1 in stage 2.0 (TID 254, ip-172-31-92-29.ec2.internal, executor 81                                                                                                                                   , partition 50, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:52 INFO TaskSetManager: Starting task 51.1 in stage 2.0 (TID 255, ip-172-31-92-29.ec2.internal, executor 81                                                                                                                                   , partition 51, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:52 INFO TaskSetManager: Starting task 48.1 in stage 2.0 (TID 256, ip-172-31-92-29.ec2.internal, executor 81                                                                                                                                   , partition 48, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:52 INFO TaskSetManager: Starting task 49.1 in stage 2.0 (TID 257, ip-172-31-92-29.ec2.internal, executor 81                                                                                                                                   , partition 49, PROCESS_LOCAL, 7673 bytes)
20/08/13 20:38:52 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-92-29.ec2.internal:40579 with 414.4                                                                                                                                    MB RAM, BlockManagerId(81, ip-172-31-92-29.ec2.internal, 40579, None)
20/08/13 20:38:53 INFO YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 78.
20/08/13 20:38:53 INFO DAGScheduler: Executor lost: 78 (epoch 2)
20/08/13 20:38:53 INFO BlockManagerMasterEndpoint: Trying to remove executor 78 from BlockManagerMaster.
20/08/13 20:38:53 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(78, ip-172-31-92-29.ec2.internal,                                                                                                                                    33233, None)
20/08/13 20:38:53 INFO BlockManagerMaster: Removed 78 successfully in removeExecutor
20/08/13 20:38:53 ERROR YarnScheduler: Lost executor 78 on ip-172-31-92-29.ec2.internal: Container killed by YARN for exce                                                                                                                                   eding memory limits.  1.6 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disab                                                                                                                                   ling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:53 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 78 for reason Cont                                                                                                                                   ainer killed by YARN for exceeding memory limits.  1.6 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.exe                                                                                                                                   cutor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:53 WARN TaskSetManager: Lost task 77.0 in stage 2.0 (TID 227, ip-172-31-92-29.ec2.internal, executor 78): E                                                                                                                                   xecutorLostFailure (executor 78 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.6 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:53 WARN TaskSetManager: Lost task 76.0 in stage 2.0 (TID 226, ip-172-31-92-29.ec2.internal, executor 78): E                                                                                                                                   xecutorLostFailure (executor 78 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.6 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:53 WARN TaskSetManager: Lost task 79.0 in stage 2.0 (TID 229, ip-172-31-92-29.ec2.internal, executor 78): E                                                                                                                                   xecutorLostFailure (executor 78 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.6 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:53 WARN TaskSetManager: Lost task 78.0 in stage 2.0 (TID 228, ip-172-31-92-29.ec2.internal, executor 78): E                                                                                                                                   xecutorLostFailure (executor 78 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.6 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:53 INFO BlockManagerMaster: Removal of executor 78 requested
20/08/13 20:38:53 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 78
20/08/13 20:38:53 INFO BlockManagerMasterEndpoint: Trying to remove executor 78 from BlockManagerMaster.
20/08/13 20:38:53 INFO ExecutorAllocationManager: Existing executor 78 has been removed (new total is 22)
20/08/13 20:38:53 WARN ExecutorAllocationManager: Attempted to mark unknown executor 78 idle
20/08/13 20:38:53 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-81-193.ec2.internal:33923 with 414.                                                                                                                                   4 MB RAM, BlockManagerId(71, ip-172-31-81-193.ec2.internal, 33923, None)
20/08/13 20:38:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-92-29.ec2.internal:40579 (size: 7                                                                                                                                   .4 KB, free: 414.4 MB)
20/08/13 20:38:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.92.29:53                                                                                                                                   174
20/08/13 20:38:55 INFO YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 82.
20/08/13 20:38:55 INFO DAGScheduler: Executor lost: 82 (epoch 2)
20/08/13 20:38:55 INFO BlockManagerMasterEndpoint: Trying to remove executor 82 from BlockManagerMaster.
20/08/13 20:38:55 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(82, ip-172-31-89-202.ec2.internal                                                                                                                                   , 44939, None)
20/08/13 20:38:55 INFO BlockManagerMaster: Removed 82 successfully in removeExecutor
20/08/13 20:38:55 ERROR YarnScheduler: Lost executor 82 on ip-172-31-89-202.ec2.internal: Container killed by YARN for exc                                                                                                                                   eeding memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disa                                                                                                                                   bling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:55 WARN TaskSetManager: Lost task 4.3 in stage 2.0 (TID 247, ip-172-31-89-202.ec2.internal, executor 82): E                                                                                                                                   xecutorLostFailure (executor 82 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling y                                                                                                                                   arn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:55 ERROR TaskSetManager: Task 4 in stage 2.0 failed 4 times; aborting job
20/08/13 20:38:55 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 82 for reason Cont                                                                                                                                   ainer killed by YARN for exceeding memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.exe                                                                                                                                   cutor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:55 WARN TaskSetManager: Lost task 18.3 in stage 2.0 (TID 249, ip-172-31-89-202.ec2.internal, executor 82):                                                                                                                                    ExecutorLostFailure (executor 82 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:55 WARN TaskSetManager: Lost task 25.3 in stage 2.0 (TID 246, ip-172-31-89-202.ec2.internal, executor 82):                                                                                                                                    ExecutorLostFailure (executor 82 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:55 WARN TaskSetManager: Lost task 11.3 in stage 2.0 (TID 248, ip-172-31-89-202.ec2.internal, executor 82):                                                                                                                                    ExecutorLostFailure (executor 82 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding                                                                                                                                    memory limits.  1.4 GB of 1.4 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling                                                                                                                                    yarn.nodemanager.vmem-check-enabled because of YARN-4714.
20/08/13 20:38:55 INFO ExecutorAllocationManager: Existing executor 82 has been removed (new total is 21)
20/08/13 20:38:55 INFO BlockManagerMasterEndpoint: Trying to remove executor 82 from BlockManagerMaster.
20/08/13 20:38:55 INFO BlockManagerMaster: Removal of executor 82 requested
20/08/13 20:38:55 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 82
20/08/13 20:38:55 INFO YarnScheduler: Cancelling stage 2
20/08/13 20:38:55 INFO YarnScheduler: Killing all running tasks in stage 2: Stage cancelled
20/08/13 20:38:55 INFO YarnScheduler: Stage 2 was cancelled
20/08/13 20:38:55 INFO DAGScheduler: ResultStage 2 (sortByKey at /home/hadoop/MovieSimilarities1M.py:90) failed in 71.777                                                                                                                                    s due to Job aborted due to stage failure: Task 4 in stage 2.0 failed 4 times, most recent failure: Lost task 4.3 in stage                                                                                                                                    2.0 (TID 247, ip-172-31-89-202.ec2.internal, executor 82): ExecutorLostFailure (executor 82 exited caused by one of the r                                                                                                                                   unning tasks) Reason: Container killed by YARN for exceeding memory limits.  1.4 GB of 1.4 GB physical memory used. Consid                                                                                                                                   er boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
Driver stacktrace:
20/08/13 20:38:55 INFO DAGScheduler: Job 0 failed: sortByKey at /home/hadoop/MovieSimilarities1M.py:90, took 406.948522 s
20/08/13 20:38:55 WARN ExecutorAllocationManager: Attempted to mark unknown executor 82 idle
Traceback (most recent call last):
  File "/home/hadoop/MovieSimilarities1M.py", line 90, in <module>
    moviePairSimilarities.sortByKey()
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 667, in sortByKey
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1055, in count
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1046, in sum
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 917, in fold
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 816, in collect
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 2.0 failed 4 times, most recent failu                                                                                                                                   re: Lost task 4.3 in stage 2.0 (TID 247, ip-172-31-89-202.ec2.internal, executor 82): ExecutorLostFailure (executor 82 exi                                                                                                                                   ted caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.4 GB of 1.4 GB ph                                                                                                                                   ysical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled                                                                                                                                    because of YARN-4714.
Driver stacktrace:
        at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DA                                                                                                                                   GScheduler.scala:2043)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2031)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2030)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2030)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:967)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:967)
        at scala.Option.foreach(Option.scala:257)
        at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:967)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2264)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2213)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2202)
        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:778)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
        at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
        at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
        at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
        at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)
        at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
        at py4j.Gateway.invoke(Gateway.java:282)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.GatewayConnection.run(GatewayConnection.java:238)
        at java.lang.Thread.run(Thread.java:748)

20/08/13 20:38:55 INFO SparkContext: Invoking stop() from shutdown hook
20/08/13 20:38:55 INFO SparkUI: Stopped Spark web UI at http://ip-172-31-90-58.ec2.internal:4040
20/08/13 20:38:55 INFO YarnClientSchedulerBackend: Interrupting monitor thread
20/08/13 20:38:55 INFO YarnClientSchedulerBackend: Shutting down all executors
20/08/13 20:38:55 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/08/13 20:38:55 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/08/13 20:38:55 INFO YarnClientSchedulerBackend: Stopped
20/08/13 20:38:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/08/13 20:38:55 INFO MemoryStore: MemoryStore cleared
20/08/13 20:38:55 INFO BlockManager: BlockManager stopped
20/08/13 20:38:55 INFO BlockManagerMaster: BlockManagerMaster stopped
20/08/13 20:38:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/08/13 20:38:55 INFO SparkContext: Successfully stopped SparkContext
20/08/13 20:38:55 INFO ShutdownHookManager: Shutdown hook called
20/08/13 20:38:55 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-b45be63b-e188-4033-bdc8-56a43036b0e1/pyspark                                                                                                                                   -39a3cb2e-5a29-4914-9a83-75fa4809b873
20/08/13 20:38:55 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-b45be63b-e188-4033-bdc8-56a43036b0e1
20/08/13 20:38:55 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-48c553da-c4d9-41e5-aa91-1aa273b21f0a
[hadoop@ip-172-31-90-58 ~]$
